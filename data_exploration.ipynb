{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, log_loss, plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split , GridSearchCV, RandomizedSearchCV, KFold, StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __READ DATA__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"trainData.csv\")\n",
    "test_data = pd.read_csv(\"testData.csv\")\n",
    "example_result = pd.read_csv(\"ornekSonuc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v10</th>\n",
       "      <th>v100</th>\n",
       "      <th>v101</th>\n",
       "      <th>v102</th>\n",
       "      <th>v103</th>\n",
       "      <th>v11</th>\n",
       "      <th>v12</th>\n",
       "      <th>v13</th>\n",
       "      <th>v14</th>\n",
       "      <th>...</th>\n",
       "      <th>v91</th>\n",
       "      <th>v92</th>\n",
       "      <th>v93</th>\n",
       "      <th>v94</th>\n",
       "      <th>v95</th>\n",
       "      <th>v96</th>\n",
       "      <th>v97</th>\n",
       "      <th>v98</th>\n",
       "      <th>v99</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    v1  v10  v100  v101  v102  v103  v11  v12  v13  v14  ...  v91  v92  v93  \\\n",
       "0  1.4  0.0   0.2   1.0   4.2   0.4  0.0  0.0  0.0  1.2  ...  0.6  0.2  0.0   \n",
       "1  0.0  0.0   0.0   2.8   0.0   0.8  0.0  0.2  1.2  1.4  ...  0.0  0.0  1.2   \n",
       "2  0.0  0.0   0.0   0.4   0.0   0.6  0.8  0.0  0.0  0.2  ...  0.0  0.0  0.0   \n",
       "3  0.0  0.0   0.0   0.0   0.2   0.8  0.4  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4  0.0  0.0   0.0   0.0   0.0   0.0  0.0  0.0  0.0  0.2  ...  0.0  0.2  0.0   \n",
       "\n",
       "   v94  v95  v96  v97  v98  v99  target  \n",
       "0  3.2  1.0  0.2  0.0  1.6  0.4       9  \n",
       "1  0.0  1.2  0.2  0.2  2.6  2.2       6  \n",
       "2  0.0  0.8  0.2  0.8  1.4  0.0       3  \n",
       "3  0.4  0.4  0.0  0.4  0.4  0.0       4  \n",
       "4  0.0  0.0  0.0  0.0  0.4  0.0       3  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v10</th>\n",
       "      <th>v100</th>\n",
       "      <th>v101</th>\n",
       "      <th>v102</th>\n",
       "      <th>v103</th>\n",
       "      <th>v11</th>\n",
       "      <th>v12</th>\n",
       "      <th>v13</th>\n",
       "      <th>v14</th>\n",
       "      <th>...</th>\n",
       "      <th>v90</th>\n",
       "      <th>v91</th>\n",
       "      <th>v92</th>\n",
       "      <th>v93</th>\n",
       "      <th>v94</th>\n",
       "      <th>v95</th>\n",
       "      <th>v96</th>\n",
       "      <th>v97</th>\n",
       "      <th>v98</th>\n",
       "      <th>v99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    v1  v10  v100  v101  v102  v103  v11  v12  v13  v14  ...  v90  v91  v92  \\\n",
       "0  0.0  0.0   0.0   0.0   0.2   0.2  0.6  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       "1  0.0  0.0   0.0   5.2   0.0   0.0  0.0  0.0  1.6  0.8  ...  0.0  0.0  0.8   \n",
       "2  0.0  0.0   0.8   2.2   0.0   0.4  0.0  0.0  0.2  0.0  ...  0.0  0.0  0.4   \n",
       "3  0.0  0.0   0.0   0.4   0.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4  0.0  0.6   0.2   0.0   0.0   0.4  0.0  0.0  0.0  0.8  ...  0.0  0.0  0.6   \n",
       "\n",
       "   v93  v94  v95  v96  v97  v98  v99  \n",
       "0  0.0  0.0  0.4  0.2  0.6  5.0  0.0  \n",
       "1  0.0  0.0  3.6  0.4  0.0  2.4  0.0  \n",
       "2  0.0  0.2  1.6  0.6  0.0  0.6  1.6  \n",
       "3  0.0  0.0  2.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.2  0.2  0.6  0.8  0.0  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c1  c2  c3  c4  c5  c6  c7  c8  c9\n",
       "0   1   0   0   0   0   0   0   0   0\n",
       "1   1   0   0   0   0   0   0   0   0\n",
       "2   1   0   0   0   0   0   0   0   0\n",
       "3   1   0   0   0   0   0   0   0   0\n",
       "4   1   0   0   0   0   0   0   0   0"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144363</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144364</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144365</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144366</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144367</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144368 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        c1  c2  c3  c4  c5  c6  c7  c8  c9\n",
       "0        1   0   0   0   0   0   0   0   0\n",
       "1        1   0   0   0   0   0   0   0   0\n",
       "2        1   0   0   0   0   0   0   0   0\n",
       "3        1   0   0   0   0   0   0   0   0\n",
       "4        1   0   0   0   0   0   0   0   0\n",
       "...     ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
       "144363   1   0   0   0   0   0   0   0   0\n",
       "144364   1   0   0   0   0   0   0   0   0\n",
       "144365   1   0   0   0   0   0   0   0   0\n",
       "144366   1   0   0   0   0   0   0   0   0\n",
       "144367   1   0   0   0   0   0   0   0   0\n",
       "\n",
       "[144368 rows x 9 columns]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __GET X(WITHOUT TARGET) AND Y(ONLY TARGET) FROM TRAIN DATA__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(columns=[\"target\"])\n",
    "y = train_data[[\"target\"]]\n",
    "\n",
    "target_labels = train_data[\"target\"].unique()\n",
    "target_labels = sorted(target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v10</th>\n",
       "      <th>v100</th>\n",
       "      <th>v101</th>\n",
       "      <th>v102</th>\n",
       "      <th>v103</th>\n",
       "      <th>v11</th>\n",
       "      <th>v12</th>\n",
       "      <th>v13</th>\n",
       "      <th>v14</th>\n",
       "      <th>...</th>\n",
       "      <th>v90</th>\n",
       "      <th>v91</th>\n",
       "      <th>v92</th>\n",
       "      <th>v93</th>\n",
       "      <th>v94</th>\n",
       "      <th>v95</th>\n",
       "      <th>v96</th>\n",
       "      <th>v97</th>\n",
       "      <th>v98</th>\n",
       "      <th>v99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61873</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61874</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61875</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61876</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61877</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61878 rows Ã— 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1  v10  v100  v101  v102  v103  v11  v12  v13  v14  ...  v90  v91  \\\n",
       "0      1.4  0.0   0.2   1.0   4.2   0.4  0.0  0.0  0.0  1.2  ...  0.2  0.6   \n",
       "1      0.0  0.0   0.0   2.8   0.0   0.8  0.0  0.2  1.2  1.4  ...  0.0  0.0   \n",
       "2      0.0  0.0   0.0   0.4   0.0   0.6  0.8  0.0  0.0  0.2  ...  0.0  0.0   \n",
       "3      0.0  0.0   0.0   0.0   0.2   0.8  0.4  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "4      0.0  0.0   0.0   0.0   0.0   0.0  0.0  0.0  0.0  0.2  ...  0.0  0.0   \n",
       "...    ...  ...   ...   ...   ...   ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "61873  0.0  0.0   0.0   0.0   0.0   1.2  1.8  0.0  0.0  0.2  ...  0.0  0.0   \n",
       "61874  0.0  0.0   0.2   0.0   0.0   0.2  0.0  0.0  0.0  1.0  ...  0.0  0.0   \n",
       "61875  0.0  0.2   0.0   0.0   0.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "61876  0.0  0.0   0.0   0.0   0.0   0.2  0.0  0.0  0.0  0.4  ...  0.2  0.0   \n",
       "61877  0.0  0.0   0.0   0.0   0.6   0.0  0.0  0.0  0.0  0.8  ...  0.0  0.0   \n",
       "\n",
       "       v92  v93  v94  v95  v96  v97  v98  v99  \n",
       "0      0.2  0.0  3.2  1.0  0.2  0.0  1.6  0.4  \n",
       "1      0.0  1.2  0.0  1.2  0.2  0.2  2.6  2.2  \n",
       "2      0.0  0.0  0.0  0.8  0.2  0.8  1.4  0.0  \n",
       "3      0.0  0.0  0.4  0.4  0.0  0.4  0.4  0.0  \n",
       "4      0.2  0.0  0.0  0.0  0.0  0.0  0.4  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "61873  0.0  0.0  0.0  0.2  0.0  1.8  0.8  0.0  \n",
       "61874  0.4  0.0  0.6  0.2  0.0  0.0  1.0  1.4  \n",
       "61875  0.6  0.0  0.2  0.0  0.0  0.2  0.0  0.0  \n",
       "61876  0.4  0.0  0.0  0.0  0.0  0.0  0.4  0.0  \n",
       "61877  0.2  0.0  0.0  0.0  0.0  0.0  0.8  0.0  \n",
       "\n",
       "[61878 rows x 103 columns]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61873</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61874</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61875</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61876</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61877</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61878 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target\n",
       "0           9\n",
       "1           6\n",
       "2           3\n",
       "3           4\n",
       "4           3\n",
       "...       ...\n",
       "61873       4\n",
       "61874       6\n",
       "61875       8\n",
       "61876       5\n",
       "61877       3\n",
       "\n",
       "[61878 rows x 1 columns]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Random Forest Classifier__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/my_env/lib/python3.7/site-packages/sklearn/model_selection/_search.py:739: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=42, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [200, 500, 700, 900]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_log_loss', verbose=0)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = { \n",
    "    'n_estimators': [200, 500, 700, 900],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "kfold = KFold(n_splits=3, random_state=42, shuffle=True)\n",
    "rf_clf = RandomForestClassifier()\n",
    "gridsearch_rf = GridSearchCV(estimator=rf_clf, param_grid=parameters, n_jobs=-1, cv=kfold, scoring=\"neg_log_loss\")\n",
    "gridsearch_rf.fit(X_train_rf, y_train_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_features': 'auto', 'n_estimators': 900}"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/my_env/lib/python3.7/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8078215901745314\n",
      "Logloss:  0.5747831417321704\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=42, max_features='auto', n_estimators= 700, criterion='gini')\n",
    "rf_clf.fit(X_train_rf, y_train_rf)\n",
    "y_pred_rf = clf1.predict(X_test_rf)\n",
    "rf_probs = clf1.predict_proba(X_test_rf)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_rf, y_pred_rf))\n",
    "score = log_loss(y_test_rf, rf_probs)\n",
    "print(\"Logloss: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_labels</th>\n",
       "      <th>predicted_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15465</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15466</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15467</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15468</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15469</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15470 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       true_labels  predicted_labels\n",
       "0                7                 3\n",
       "1                2                 2\n",
       "2                2                 2\n",
       "3                9                 9\n",
       "4                5                 5\n",
       "...            ...               ...\n",
       "15465            3                 3\n",
       "15466            2                 2\n",
       "15467            2                 2\n",
       "15468            8                 8\n",
       "15469            2                 2\n",
       "\n",
       "[15470 rows x 2 columns]"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_comparison_df = pd.DataFrame()\n",
    "rf_comparison_df['true_labels'] = y_test_rf['target'].tolist()\n",
    "rf_comparison_df['predicted_labels'] = y_pred_rf\n",
    "rf_comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.404286</td>\n",
       "      <td>0.418571</td>\n",
       "      <td>0.112857</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.048571</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.004286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.777143</td>\n",
       "      <td>0.184286</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.001429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.067143</td>\n",
       "      <td>0.044286</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.084286</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.881429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.075714</td>\n",
       "      <td>0.015714</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.884286</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15465</th>\n",
       "      <td>0.051429</td>\n",
       "      <td>0.311429</td>\n",
       "      <td>0.388571</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.027143</td>\n",
       "      <td>0.027143</td>\n",
       "      <td>0.141429</td>\n",
       "      <td>0.045714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15466</th>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.808571</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.025714</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15467</th>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.721429</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15468</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.037143</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.944286</td>\n",
       "      <td>0.002857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15469</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.951429</td>\n",
       "      <td>0.024286</td>\n",
       "      <td>0.022857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15470 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1         2         3         4         5         6         7  \\\n",
       "0      0.002857  0.404286  0.418571  0.112857  0.001429  0.005714  0.048571   \n",
       "1      0.000000  0.777143  0.184286  0.028571  0.000000  0.000000  0.001429   \n",
       "2      0.004286  0.860000  0.067143  0.044286  0.001429  0.007143  0.014286   \n",
       "3      0.084286  0.004286  0.000000  0.000000  0.005714  0.010000  0.004286   \n",
       "4      0.005714  0.075714  0.015714  0.005714  0.884286  0.007143  0.002857   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "15465  0.051429  0.311429  0.388571  0.004286  0.002857  0.027143  0.027143   \n",
       "15466  0.008571  0.808571  0.120000  0.025714  0.008571  0.005714  0.001429   \n",
       "15467  0.001429  0.721429  0.242857  0.028571  0.000000  0.000000  0.005714   \n",
       "15468  0.000000  0.002857  0.001429  0.000000  0.002857  0.037143  0.008571   \n",
       "15469  0.000000  0.951429  0.024286  0.022857  0.000000  0.000000  0.001429   \n",
       "\n",
       "              8         9  \n",
       "0      0.001429  0.004286  \n",
       "1      0.007143  0.001429  \n",
       "2      0.001429  0.000000  \n",
       "3      0.010000  0.881429  \n",
       "4      0.001429  0.001429  \n",
       "...         ...       ...  \n",
       "15465  0.141429  0.045714  \n",
       "15466  0.011429  0.010000  \n",
       "15467  0.000000  0.000000  \n",
       "15468  0.944286  0.002857  \n",
       "15469  0.000000  0.000000  \n",
       "\n",
       "[15470 rows x 9 columns]"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_submission_df = pd.DataFrame(columns=[[\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]], data=rf_probs)\n",
    "rf_submission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __XGBoost Classifier__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_xgb, X_test_xgb, y_train_xgb, y_test_xgb = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"colsample_bytree\":[0.3,0.4, 0.45, 0.6, 0.8, 1.0], \n",
    "              \"learning_rate\":[0.1, 0.2, 0.3],\n",
    "              \"n_estimators\":[300, 500, 700, 800, 900],\n",
    "              \"gamma\":[0.0001, 0.001, 0.01],\n",
    "              'min_child_weight': [1, 5, 10],\n",
    "              'subsample': [0.6, 0.8, 1.0]\n",
    "             }\n",
    "\n",
    "xgb_clf_gs = xgb.XGBClassifier(objective=\"multi:softmax\", eval_metric=\"logloss\")\n",
    "\n",
    "folds = 3\n",
    "param_comb = 6\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb_clf_gs, param_distributions=parameters, n_iter=param_comb, scoring='neg_log_loss', n_jobs=-1, cv=skf.split(X_train, y_train), verbose=3, random_state=1001)\n",
    "\n",
    "start_time = time.time()\n",
    "random_search.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Time: \", end_time - start_time())\n",
    "\n",
    "# xgb_clf_gs = xgb.XGBClassifier(eval_metric=\"logloss\", n_estimators=700, learning_rate=0.1, gamma=0.001, max_depth=6, n_jobs=-1, booster='gbtree')\n",
    "# gridsearch_xgb = GridSearchCV(estimator=clf, param_grid=parameters, n_jobs=-1, cv=kfold, scoring=\"neg_log_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.8,\n",
       " 'n_estimators': 300,\n",
       " 'min_child_weight': 5,\n",
       " 'learning_rate': 0.1,\n",
       " 'gamma': 0.01,\n",
       " 'colsample_bytree': 0.3}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/my_env/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/envs/my_env/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:26:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Accuracy: 0.8263089851325145\n",
      "Logloss:  0.4597055968460563\n"
     ]
    }
   ],
   "source": [
    "# xgb_clf = xgb.XGBClassifier(objective=\"multi:softmax\", eval_metric=\"mlogloss\", n_estimators=700, learning_rate=0.1, gamma=0.01, max_depth=6, n_jobs=-1, booster='gbtree', colsample_bytree=0.3, min_child_weight=5, subsample=0.8)\n",
    "xgb_clf = xgb.XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
    "              colsample_bynode=None, colsample_bytree=0.6, gamma=0, gpu_id=None,\n",
    "              importance_type='gain', interaction_constraints=None,\n",
    "              learning_rate=0.03, max_delta_step=0, max_depth=28,\n",
    "              min_child_weight=6, monotone_constraints=None,\n",
    "              n_estimators=700, n_jobs=None, nthread=-1, num_parallel_tree=None,\n",
    "              objective='multi:softmax', random_state=None, reg_alpha=0,\n",
    "              reg_lambda=1, scale_pos_weight=1, seed=0, silent=True,\n",
    "              subsample=0.8, tree_method=None, validate_parameters=None,\n",
    "              verbosity=None)\n",
    "\n",
    "xgb_clf.fit(X_train_xgb, y_train_xgb)\n",
    "y_pred_xgb = xgb_clf.predict(X_test_xgb)\n",
    "xgb_probs = xgb_clf.predict_proba(X_test_xgb)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_xgb, y_pred_xgb))\n",
    "score = log_loss(y_test_xgb, xgb_probs)\n",
    "print(\"Logloss: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.483535</td>\n",
       "      <td>0.461407</td>\n",
       "      <td>0.008990</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.045020</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.942939</td>\n",
       "      <td>0.053242</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.996814</td>\n",
       "      <td>0.001772</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.051208</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.947546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.006088</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.006163</td>\n",
       "      <td>0.984778</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15465</th>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.127151</td>\n",
       "      <td>0.859089</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.010392</td>\n",
       "      <td>0.000508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15466</th>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.992112</td>\n",
       "      <td>0.003775</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.003072</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15467</th>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.870988</td>\n",
       "      <td>0.117525</td>\n",
       "      <td>0.010680</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15468</th>\n",
       "      <td>0.001239</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.041510</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.950345</td>\n",
       "      <td>0.004920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15469</th>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.979784</td>\n",
       "      <td>0.013157</td>\n",
       "      <td>0.004936</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15470 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1         2         3         4         5         6         7  \\\n",
       "0      0.000207  0.483535  0.461407  0.008990  0.000065  0.000521  0.045020   \n",
       "1      0.000094  0.942939  0.053242  0.003091  0.000048  0.000093  0.000232   \n",
       "2      0.000012  0.996814  0.001772  0.001270  0.000016  0.000023  0.000060   \n",
       "3      0.051208  0.000097  0.000060  0.000040  0.000130  0.000481  0.000133   \n",
       "4      0.000532  0.006088  0.001074  0.006163  0.984778  0.000054  0.001068   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "15465  0.000654  0.127151  0.859089  0.000183  0.000717  0.000837  0.000470   \n",
       "15466  0.000056  0.992112  0.003775  0.000456  0.003072  0.000103  0.000062   \n",
       "15467  0.000148  0.870988  0.117525  0.010680  0.000065  0.000075  0.000275   \n",
       "15468  0.001239  0.000090  0.000229  0.000840  0.000045  0.041510  0.000783   \n",
       "15469  0.000110  0.979784  0.013157  0.004936  0.000064  0.001218  0.000377   \n",
       "\n",
       "              8         9  \n",
       "0      0.000141  0.000115  \n",
       "1      0.000182  0.000080  \n",
       "2      0.000011  0.000021  \n",
       "3      0.000304  0.947546  \n",
       "4      0.000134  0.000108  \n",
       "...         ...       ...  \n",
       "15465  0.010392  0.000508  \n",
       "15466  0.000284  0.000081  \n",
       "15467  0.000130  0.000114  \n",
       "15468  0.950345  0.004920  \n",
       "15469  0.000235  0.000117  \n",
       "\n",
       "[15470 rows x 9 columns]"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_prob = pd.DataFrame(data=xgb_probs, columns=[\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"])\n",
    "xgb_prob.to_csv(\"trial/second_trial/xgb_second_predictions_probabilities.csv\")\n",
    "xgb_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15465</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15466</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15467</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15468</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15469</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15470 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0      2\n",
       "1      2\n",
       "2      2\n",
       "3      9\n",
       "4      5\n",
       "...   ..\n",
       "15465  3\n",
       "15466  2\n",
       "15467  2\n",
       "15468  8\n",
       "15469  2\n",
       "\n",
       "[15470 rows x 1 columns]"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_pred_classes = pd.DataFrame(data=y_pred_xgb)\n",
    "xgb_pred_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __KERAS MULTICLASS CLASSIFICATION__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import datetime, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "early_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "X_normalized_df = pd.DataFrame(X_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dummies = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.072165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.313433</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.060241</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030075</td>\n",
       "      <td>0.021978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.026616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.072289</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.048872</td>\n",
       "      <td>0.120879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.048193</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.045977</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.024096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61873</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.015038</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61874</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018797</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61875</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61876</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61877</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015038</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61878 rows Ã— 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "0      0.072165  0.000000  0.011765  0.065789  0.313433  0.026316  0.000000   \n",
       "1      0.000000  0.000000  0.000000  0.184211  0.000000  0.052632  0.000000   \n",
       "2      0.000000  0.000000  0.000000  0.026316  0.000000  0.039474  0.121212   \n",
       "3      0.000000  0.000000  0.000000  0.000000  0.014925  0.052632  0.060606   \n",
       "4      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "61873  0.000000  0.000000  0.000000  0.000000  0.000000  0.078947  0.272727   \n",
       "61874  0.000000  0.000000  0.011765  0.000000  0.000000  0.013158  0.000000   \n",
       "61875  0.000000  0.011494  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "61876  0.000000  0.000000  0.000000  0.000000  0.000000  0.013158  0.000000   \n",
       "61877  0.000000  0.000000  0.000000  0.000000  0.044776  0.000000  0.000000   \n",
       "\n",
       "            7         8         9    ...       93        94        95     96   \\\n",
       "0      0.000000  0.000000  0.022814  ...  0.032258  0.136364  0.020408  0.000   \n",
       "1      0.016129  0.057143  0.026616  ...  0.000000  0.000000  0.000000  0.125   \n",
       "2      0.000000  0.000000  0.003802  ...  0.000000  0.000000  0.000000  0.000   \n",
       "3      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000   \n",
       "4      0.000000  0.000000  0.003802  ...  0.000000  0.000000  0.020408  0.000   \n",
       "...         ...       ...       ...  ...       ...       ...       ...    ...   \n",
       "61873  0.000000  0.000000  0.003802  ...  0.000000  0.000000  0.000000  0.000   \n",
       "61874  0.000000  0.000000  0.019011  ...  0.000000  0.000000  0.040816  0.000   \n",
       "61875  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.061224  0.000   \n",
       "61876  0.000000  0.000000  0.007605  ...  0.032258  0.000000  0.040816  0.000   \n",
       "61877  0.000000  0.000000  0.015209  ...  0.000000  0.000000  0.020408  0.000   \n",
       "\n",
       "        97        98        99        100       101       102  \n",
       "0      0.16  0.060241  0.013158  0.000000  0.030075  0.021978  \n",
       "1      0.00  0.072289  0.013158  0.011494  0.048872  0.120879  \n",
       "2      0.00  0.048193  0.013158  0.045977  0.026316  0.000000  \n",
       "3      0.02  0.024096  0.000000  0.022989  0.007519  0.000000  \n",
       "4      0.00  0.000000  0.000000  0.000000  0.007519  0.000000  \n",
       "...     ...       ...       ...       ...       ...       ...  \n",
       "61873  0.00  0.012048  0.000000  0.103448  0.015038  0.000000  \n",
       "61874  0.03  0.012048  0.000000  0.000000  0.018797  0.076923  \n",
       "61875  0.01  0.000000  0.000000  0.011494  0.000000  0.000000  \n",
       "61876  0.00  0.000000  0.000000  0.000000  0.007519  0.000000  \n",
       "61877  0.00  0.000000  0.000000  0.000000  0.015038  0.000000  \n",
       "\n",
       "[61878 rows x 103 columns]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61873</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61874</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61875</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61876</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61877</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61878 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target\n",
       "0           9\n",
       "1           6\n",
       "2           3\n",
       "3           4\n",
       "4           3\n",
       "...       ...\n",
       "61873       4\n",
       "61874       6\n",
       "61875       8\n",
       "61876       5\n",
       "61877       3\n",
       "\n",
       "[61878 rows x 1 columns]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized_df, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Keras, convert dataframe to array values (Inbuilt requirement of Keras)\n",
    "X_train_array = X_train.values\n",
    "y__train_array = y_train.values\n",
    "X_test_array = X_test.values\n",
    "y_test_array = y_test.values\n",
    "\n",
    "in_dim = X_train_array.shape[1]\n",
    "out_dim = y__train_array.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Model\n",
    "def baseline_model():\n",
    "    # Create model here\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim = in_dim, activation = 'relu')) # Rectified Linear Unit Activation Function\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dense(16, activation=\"relu\"))\n",
    "    model.add(Dense(10, activation = 'softmax')) # Softmax for multi-class classification\n",
    "    # Compile model here\n",
    "#     model.add(Dense(out_dim))\n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Keras Classifier and use predefined baseline model\n",
    "estimator = KerasClassifier(build_fn = baseline_model, epochs = 100, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold Cross Validation\n",
    "kfold = KFold(n_splits = 5, shuffle = True, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49502 samples, validate on 12376 samples\n",
      "Epoch 1/100\n",
      "49502/49502 [==============================] - 3s 55us/step - loss: 0.7991 - accuracy: 0.7106 - val_loss: 5.3141 - val_accuracy: 0.0554\n",
      "Epoch 2/100\n",
      "49502/49502 [==============================] - 2s 50us/step - loss: 0.6134 - accuracy: 0.7638 - val_loss: 6.0422 - val_accuracy: 0.0520\n",
      "Epoch 3/100\n",
      "49502/49502 [==============================] - 2s 50us/step - loss: 0.5720 - accuracy: 0.7750 - val_loss: 6.2049 - val_accuracy: 0.0326\n",
      "Epoch 4/100\n",
      "49502/49502 [==============================] - 2s 50us/step - loss: 0.5454 - accuracy: 0.7860 - val_loss: 7.0680 - val_accuracy: 0.0726\n",
      "Epoch 5/100\n",
      "49502/49502 [==============================] - 2s 50us/step - loss: 0.5249 - accuracy: 0.7924 - val_loss: 7.5831 - val_accuracy: 0.0525\n",
      "Epoch 6/100\n",
      "49502/49502 [==============================] - 2s 50us/step - loss: 0.5096 - accuracy: 0.7974 - val_loss: 8.3474 - val_accuracy: 0.0755\n",
      "Epoch 7/100\n",
      "49502/49502 [==============================] - 2s 50us/step - loss: 0.4936 - accuracy: 0.8037 - val_loss: 7.6128 - val_accuracy: 0.0658\n",
      "Epoch 8/100\n",
      "49502/49502 [==============================] - 3s 52us/step - loss: 0.4798 - accuracy: 0.8080 - val_loss: 9.4012 - val_accuracy: 0.0237\n",
      "Epoch 9/100\n",
      "49502/49502 [==============================] - 3s 52us/step - loss: 0.4666 - accuracy: 0.8128 - val_loss: 9.3280 - val_accuracy: 0.0511\n",
      "Epoch 10/100\n",
      "49502/49502 [==============================] - 2s 50us/step - loss: 0.4560 - accuracy: 0.8172 - val_loss: 9.3910 - val_accuracy: 0.0599\n",
      "Epoch 11/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.4433 - accuracy: 0.8215 - val_loss: 10.0373 - val_accuracy: 0.0581\n",
      "Epoch 12/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.4330 - accuracy: 0.8263 - val_loss: 10.4908 - val_accuracy: 0.0383\n",
      "Epoch 13/100\n",
      "49502/49502 [==============================] - 2s 50us/step - loss: 0.4230 - accuracy: 0.8274 - val_loss: 11.6618 - val_accuracy: 0.0246\n",
      "Epoch 14/100\n",
      "49502/49502 [==============================] - 2s 50us/step - loss: 0.4121 - accuracy: 0.8331 - val_loss: 11.3662 - val_accuracy: 0.0616\n",
      "Epoch 15/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.4015 - accuracy: 0.8377 - val_loss: 11.1171 - val_accuracy: 0.1042\n",
      "Epoch 16/100\n",
      "49502/49502 [==============================] - 3s 52us/step - loss: 0.3930 - accuracy: 0.8403 - val_loss: 11.3748 - val_accuracy: 0.0477\n",
      "Epoch 17/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.3819 - accuracy: 0.8452 - val_loss: 12.3916 - val_accuracy: 0.0517\n",
      "Epoch 18/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.3720 - accuracy: 0.8477 - val_loss: 13.7034 - val_accuracy: 0.0381\n",
      "Epoch 19/100\n",
      "49502/49502 [==============================] - 3s 54us/step - loss: 0.3633 - accuracy: 0.8526 - val_loss: 12.7173 - val_accuracy: 0.0650\n",
      "Epoch 20/100\n",
      "49502/49502 [==============================] - 3s 59us/step - loss: 0.3540 - accuracy: 0.8552 - val_loss: 14.8281 - val_accuracy: 0.0448\n",
      "Epoch 21/100\n",
      "49502/49502 [==============================] - 3s 57us/step - loss: 0.3456 - accuracy: 0.8580 - val_loss: 14.3523 - val_accuracy: 0.0310\n",
      "Epoch 22/100\n",
      "49502/49502 [==============================] - 3s 58us/step - loss: 0.3355 - accuracy: 0.8628 - val_loss: 14.6390 - val_accuracy: 0.0552\n",
      "Epoch 23/100\n",
      "49502/49502 [==============================] - 3s 67us/step - loss: 0.3306 - accuracy: 0.8633 - val_loss: 14.1143 - val_accuracy: 0.0409\n",
      "Epoch 24/100\n",
      "49502/49502 [==============================] - 3s 54us/step - loss: 0.3207 - accuracy: 0.8678 - val_loss: 15.3150 - val_accuracy: 0.0840\n",
      "Epoch 25/100\n",
      "49502/49502 [==============================] - 3s 58us/step - loss: 0.3133 - accuracy: 0.8719 - val_loss: 15.9996 - val_accuracy: 0.0638\n",
      "Epoch 26/100\n",
      "49502/49502 [==============================] - 3s 55us/step - loss: 0.3090 - accuracy: 0.8728 - val_loss: 15.1424 - val_accuracy: 0.0755\n",
      "Epoch 27/100\n",
      "49502/49502 [==============================] - 3s 53us/step - loss: 0.2987 - accuracy: 0.8770 - val_loss: 16.4626 - val_accuracy: 0.0486\n",
      "Epoch 28/100\n",
      "49502/49502 [==============================] - 3s 61us/step - loss: 0.2909 - accuracy: 0.8797 - val_loss: 17.3985 - val_accuracy: 0.0676\n",
      "Epoch 29/100\n",
      "49502/49502 [==============================] - 3s 58us/step - loss: 0.2844 - accuracy: 0.8836 - val_loss: 16.9931 - val_accuracy: 0.0727\n",
      "Epoch 30/100\n",
      "49502/49502 [==============================] - 2s 48us/step - loss: 0.2773 - accuracy: 0.8862 - val_loss: 17.3595 - val_accuracy: 0.0678\n",
      "Epoch 31/100\n",
      "49502/49502 [==============================] - 2s 50us/step - loss: 0.2715 - accuracy: 0.8877 - val_loss: 18.6552 - val_accuracy: 0.0610\n",
      "Epoch 32/100\n",
      "49502/49502 [==============================] - 3s 53us/step - loss: 0.2685 - accuracy: 0.8898 - val_loss: 19.9078 - val_accuracy: 0.0444\n",
      "Epoch 33/100\n",
      "49502/49502 [==============================] - 3s 57us/step - loss: 0.2573 - accuracy: 0.8940 - val_loss: 20.0018 - val_accuracy: 0.0631\n",
      "Epoch 34/100\n",
      "49502/49502 [==============================] - 3s 63us/step - loss: 0.2527 - accuracy: 0.8958 - val_loss: 18.9381 - val_accuracy: 0.0461\n",
      "Epoch 35/100\n",
      "49502/49502 [==============================] - 3s 59us/step - loss: 0.2458 - accuracy: 0.8987 - val_loss: 19.4286 - val_accuracy: 0.0442\n",
      "Epoch 36/100\n",
      "49502/49502 [==============================] - 3s 53us/step - loss: 0.2403 - accuracy: 0.9018 - val_loss: 21.3641 - val_accuracy: 0.0558\n",
      "Epoch 37/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.2336 - accuracy: 0.9039 - val_loss: 21.1010 - val_accuracy: 0.0647\n",
      "Epoch 38/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.2325 - accuracy: 0.9044 - val_loss: 22.0188 - val_accuracy: 0.0518\n",
      "Epoch 39/100\n",
      "49502/49502 [==============================] - 3s 52us/step - loss: 0.2235 - accuracy: 0.9090 - val_loss: 20.9495 - val_accuracy: 0.0509\n",
      "Epoch 40/100\n",
      "49502/49502 [==============================] - 3s 53us/step - loss: 0.2206 - accuracy: 0.9098 - val_loss: 23.5192 - val_accuracy: 0.0537\n",
      "Epoch 41/100\n",
      "49502/49502 [==============================] - 3s 54us/step - loss: 0.2149 - accuracy: 0.9125 - val_loss: 23.4937 - val_accuracy: 0.0580\n",
      "Epoch 42/100\n",
      "49502/49502 [==============================] - 3s 54us/step - loss: 0.2072 - accuracy: 0.9150 - val_loss: 23.1922 - val_accuracy: 0.0570\n",
      "Epoch 43/100\n",
      "49502/49502 [==============================] - 3s 53us/step - loss: 0.2054 - accuracy: 0.9164 - val_loss: 23.6127 - val_accuracy: 0.0615\n",
      "Epoch 44/100\n",
      "49502/49502 [==============================] - 3s 55us/step - loss: 0.1997 - accuracy: 0.9180 - val_loss: 23.7491 - val_accuracy: 0.0690\n",
      "Epoch 45/100\n",
      "49502/49502 [==============================] - 3s 60us/step - loss: 0.1946 - accuracy: 0.9203 - val_loss: 24.0137 - val_accuracy: 0.0576\n",
      "Epoch 46/100\n",
      "49502/49502 [==============================] - 3s 53us/step - loss: 0.1895 - accuracy: 0.9215 - val_loss: 25.7226 - val_accuracy: 0.0671\n",
      "Epoch 47/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.1903 - accuracy: 0.9229 - val_loss: 24.6590 - val_accuracy: 0.0781\n",
      "Epoch 48/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.1818 - accuracy: 0.9249 - val_loss: 25.1514 - val_accuracy: 0.0576\n",
      "Epoch 49/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.1817 - accuracy: 0.9259 - val_loss: 29.9384 - val_accuracy: 0.0694\n",
      "Epoch 50/100\n",
      "49502/49502 [==============================] - 3s 57us/step - loss: 0.1760 - accuracy: 0.9291 - val_loss: 28.0606 - val_accuracy: 0.0654\n",
      "Epoch 51/100\n",
      "49502/49502 [==============================] - 3s 53us/step - loss: 0.1720 - accuracy: 0.9295 - val_loss: 27.1366 - val_accuracy: 0.0557\n",
      "Epoch 52/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.1656 - accuracy: 0.9314 - val_loss: 27.5597 - val_accuracy: 0.0729\n",
      "Epoch 53/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.1659 - accuracy: 0.9317 - val_loss: 27.9335 - val_accuracy: 0.0676\n",
      "Epoch 54/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.1619 - accuracy: 0.9337 - val_loss: 27.3440 - val_accuracy: 0.0520\n",
      "Epoch 55/100\n",
      "49502/49502 [==============================] - 2s 50us/step - loss: 0.1610 - accuracy: 0.9350 - val_loss: 28.9252 - val_accuracy: 0.0562\n",
      "Epoch 56/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.1495 - accuracy: 0.9386 - val_loss: 28.6548 - val_accuracy: 0.0676\n",
      "Epoch 57/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.1546 - accuracy: 0.9386 - val_loss: 31.4873 - val_accuracy: 0.0553\n",
      "Epoch 58/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.1504 - accuracy: 0.9383 - val_loss: 31.2146 - val_accuracy: 0.0552\n",
      "Epoch 59/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.1432 - accuracy: 0.9419 - val_loss: 31.8616 - val_accuracy: 0.0546\n",
      "Epoch 60/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.1405 - accuracy: 0.9430 - val_loss: 32.4550 - val_accuracy: 0.0518\n",
      "Epoch 61/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.1419 - accuracy: 0.9433 - val_loss: 31.6003 - val_accuracy: 0.0486\n",
      "Epoch 62/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.1378 - accuracy: 0.9439 - val_loss: 32.4938 - val_accuracy: 0.0742\n",
      "Epoch 63/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.1330 - accuracy: 0.9461 - val_loss: 34.0107 - val_accuracy: 0.0502\n",
      "Epoch 64/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.1333 - accuracy: 0.9462 - val_loss: 31.2558 - val_accuracy: 0.0680\n",
      "Epoch 65/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.1307 - accuracy: 0.9478 - val_loss: 30.7840 - val_accuracy: 0.0642\n",
      "Epoch 66/100\n",
      "49502/49502 [==============================] - 3s 52us/step - loss: 0.1288 - accuracy: 0.9488 - val_loss: 33.0359 - val_accuracy: 0.0661\n",
      "Epoch 67/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.1226 - accuracy: 0.9498 - val_loss: 33.3054 - val_accuracy: 0.0701\n",
      "Epoch 68/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.1280 - accuracy: 0.9489 - val_loss: 31.2792 - val_accuracy: 0.0668\n",
      "Epoch 69/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.1169 - accuracy: 0.9536 - val_loss: 37.0559 - val_accuracy: 0.0611\n",
      "Epoch 70/100\n",
      "49502/49502 [==============================] - 3s 52us/step - loss: 0.1218 - accuracy: 0.9522 - val_loss: 34.1282 - val_accuracy: 0.0555\n",
      "Epoch 71/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.1169 - accuracy: 0.9535 - val_loss: 36.3028 - val_accuracy: 0.0751\n",
      "Epoch 72/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.1141 - accuracy: 0.9554 - val_loss: 37.9716 - val_accuracy: 0.0521\n",
      "Epoch 73/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.1122 - accuracy: 0.9569 - val_loss: 35.8753 - val_accuracy: 0.0663\n",
      "Epoch 74/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.1112 - accuracy: 0.9559 - val_loss: 35.3964 - val_accuracy: 0.0568\n",
      "Epoch 75/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.1122 - accuracy: 0.9552 - val_loss: 34.2444 - val_accuracy: 0.0610\n",
      "Epoch 76/100\n",
      "49502/49502 [==============================] - 2s 50us/step - loss: 0.1071 - accuracy: 0.9578 - val_loss: 38.2708 - val_accuracy: 0.0551\n",
      "Epoch 77/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.1104 - accuracy: 0.9577 - val_loss: 36.3140 - val_accuracy: 0.0654\n",
      "Epoch 78/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.1024 - accuracy: 0.9612 - val_loss: 32.5827 - val_accuracy: 0.0585\n",
      "Epoch 79/100\n",
      "49502/49502 [==============================] - 2s 50us/step - loss: 0.1021 - accuracy: 0.9593 - val_loss: 36.8037 - val_accuracy: 0.0602\n",
      "Epoch 80/100\n",
      "49502/49502 [==============================] - 3s 52us/step - loss: 0.1016 - accuracy: 0.9605 - val_loss: 36.8776 - val_accuracy: 0.0615\n",
      "Epoch 81/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.0993 - accuracy: 0.9614 - val_loss: 36.4339 - val_accuracy: 0.0654\n",
      "Epoch 82/100\n",
      "49502/49502 [==============================] - 2s 50us/step - loss: 0.1022 - accuracy: 0.9594 - val_loss: 36.6746 - val_accuracy: 0.0570\n",
      "Epoch 83/100\n",
      "49502/49502 [==============================] - 2s 50us/step - loss: 0.0957 - accuracy: 0.9625 - val_loss: 39.6444 - val_accuracy: 0.0646\n",
      "Epoch 84/100\n",
      "49502/49502 [==============================] - 2s 50us/step - loss: 0.0978 - accuracy: 0.9619 - val_loss: 38.1294 - val_accuracy: 0.0622\n",
      "Epoch 85/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.0899 - accuracy: 0.9650 - val_loss: 37.0332 - val_accuracy: 0.0668\n",
      "Epoch 86/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.0986 - accuracy: 0.9609 - val_loss: 37.6146 - val_accuracy: 0.0654\n",
      "Epoch 87/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.0913 - accuracy: 0.9650 - val_loss: 37.7640 - val_accuracy: 0.0723\n",
      "Epoch 88/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.0912 - accuracy: 0.9646 - val_loss: 41.3264 - val_accuracy: 0.0495\n",
      "Epoch 89/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.0924 - accuracy: 0.9656 - val_loss: 37.0421 - val_accuracy: 0.0720\n",
      "Epoch 90/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.0911 - accuracy: 0.9660 - val_loss: 41.4867 - val_accuracy: 0.0560\n",
      "Epoch 91/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.0846 - accuracy: 0.9675 - val_loss: 39.8874 - val_accuracy: 0.0493\n",
      "Epoch 92/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.0848 - accuracy: 0.9670 - val_loss: 41.9400 - val_accuracy: 0.0515\n",
      "Epoch 93/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.0885 - accuracy: 0.9658 - val_loss: 39.9671 - val_accuracy: 0.0639\n",
      "Epoch 94/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.0864 - accuracy: 0.9671 - val_loss: 41.2904 - val_accuracy: 0.0583\n",
      "Epoch 95/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.0857 - accuracy: 0.9678 - val_loss: 37.1604 - val_accuracy: 0.0621\n",
      "Epoch 96/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.0802 - accuracy: 0.9692 - val_loss: 39.9409 - val_accuracy: 0.0593\n",
      "Epoch 97/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.0809 - accuracy: 0.9691 - val_loss: 39.8945 - val_accuracy: 0.0600\n",
      "Epoch 98/100\n",
      "49502/49502 [==============================] - 2s 50us/step - loss: 0.0855 - accuracy: 0.9681 - val_loss: 41.4706 - val_accuracy: 0.0718\n",
      "Epoch 99/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.0784 - accuracy: 0.9711 - val_loss: 39.9843 - val_accuracy: 0.0527\n",
      "Epoch 100/100\n",
      "49502/49502 [==============================] - 3s 51us/step - loss: 0.0774 - accuracy: 0.9713 - val_loss: 39.7040 - val_accuracy: 0.0527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7faa8124a0d0>"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(X_train, y_train, epochs=100, batch_size=30, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = estimator.predict(X_test_array)\n",
    "matrix = confusion_matrix(y_test_array, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 9, 2, ..., 6, 4, 2])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 212,    7,    1,    2,    0,   25,   23,   40,   66],\n",
       "       [   2, 2572,  457,   99,    7,    7,   37,    7,   12],\n",
       "       [   1,  703,  744,   63,    0,    9,   36,    5,    2],\n",
       "       [   1,  162,   71,  273,    5,    3,   14,    1,    2],\n",
       "       [   3,   15,    1,    3,  553,    0,    0,    0,    0],\n",
       "       [  37,   20,    8,   15,    3, 2615,   56,   41,   49],\n",
       "       [  15,   53,   44,   13,    4,   42,  374,   19,    6],\n",
       "       [  51,   18,    5,    2,    4,   70,   19, 1533,   45],\n",
       "       [  40,   15,    1,    0,    3,   27,    7,   27,  849]])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 212    7    1    2    0   25   23   40   66]\n",
      " [   2 2572  457   99    7    7   37    7   12]\n",
      " [   1  703  744   63    0    9   36    5    2]\n",
      " [   1  162   71  273    5    3   14    1    2]\n",
      " [   3   15    1    3  553    0    0    0    0]\n",
      " [  37   20    8   15    3 2615   56   41   49]\n",
      " [  15   53   44   13    4   42  374   19    6]\n",
      " [  51   18    5    2    4   70   19 1533   45]\n",
      " [  40   15    1    0    3   27    7   27  849]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "cm = confusion_matrix(y_true=y_test_array, y_pred=predictions)\n",
    "cm_plot_labels = ['no_side_effects','had_side_effects']\n",
    "plot_confusion_matrix(cm, target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 532,\n",
       "         9: 969,\n",
       "         2: 3200,\n",
       "         6: 2844,\n",
       "         8: 1747,\n",
       "         5: 575,\n",
       "         7: 570,\n",
       "         1: 376,\n",
       "         3: 1563})"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(y_test['target'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-356-b5e79b388ce3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcomparison_df_keras\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcomparison_df_keras\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'true_labels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcomparison_df_keras\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_labels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcomparison_df_keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/my_env/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2937\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2938\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/my_env/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3000\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3001\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/my_env/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3635\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3636\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3637\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3638\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/my_env/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Length of values does not match length of index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "comparison_df_keras = pd.DataFrame()\n",
    "comparison_df_keras['true_labels'] = y_test['target'].tolist()\n",
    "comparison_df_keras['predicted_labels'] = predictions\n",
    "comparison_df_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
